{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Monte Carlo approximation: generate some (unweighted) samples from the posterior $\\mathbf { x } ^ { s } \\sim p ( \\mathbf { x } | \\mathcal { D } )$, and hten use these to compute any quantity of interest. For example: posterior marginal: $p \\left( x _ { 1 } | \\mathcal { D } \\right)$ or the posterior of the difference of two quantities: $p \\left( x _ { 1 } - x _ { 2 } | \\mathcal { D } \\right)$ or the posterior predictive $p ( y | \\mathcal { D } )$. All of these quantities can be approximated by $\\mathbb { E } [ f | \\mathcal { D } ] \\approx \\frac { 1 } { S } \\sum _ { s = 1 } ^ { S } f \\left( \\mathbf { x } ^ { s } \\right)$ for some suitable function $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non sequence sampling\n",
    "Work well in low dimensional data\n",
    "\n",
    "### Reject sampling\n",
    "When the inverse cdf method cannot be used. \n",
    "\n",
    "Basic idea: in the reject sampling, we create a proposal distribution $q(x)$ which satisfies $M q ( x ) \\geq \\tilde { p } ( x )$, for some constant $M$, where $\\tilde { p } ( x )$ is an unnormalized version of $p(x)$ (i.e. $p ( x ) = \\tilde { p } ( x ) / Z _ { p }$). The function $Mq(x)$ provides an upper envelope for $\\tilde{p}$. We then sammple $x \\sim q(x)$, which corresponds to picking a random $x$ location, and then sample $u \\sim U(0, 1)$, which corresponds to picking and random hieght ($y$ location) under the envelope. If $u > \\frac { \\tilde { p } ( x ) } { M q ( x ) }$, we reject the sample, otherwise we accept it.\n",
    "\n",
    "![](../images/23.reject.png)\n",
    "\n",
    "### Important sampling\n",
    "\n",
    "We want to approximate the integrals of the form:\n",
    "$$I = \\mathbb { E } [ f ] = \\int f ( \\mathbf { x } ) p ( \\mathbf { x } ) d \\mathbf { x }$$\n",
    "\n",
    "Basic idea: is to draw samples $\\mathbb{x}$ in regions which have high probability, $p(\\mathbb{x})$, but also where $|f(\\mathbb{x})|$ is large. The result can be super efficient, meaning it needs less samples than if we were to sample from the exact distribution $p(\\mathbb{x})$. Important sampling samples from any proposal, $q(x)$. It then uses these samples to estimate the integral as follows:\n",
    "$$\\mathbb { E } [ f ] = \\int f ( \\mathbf { x } ) \\frac { p ( \\mathbf { x } ) } { q ( \\mathbf { x } ) } q ( \\mathbf { x } ) d \\mathbf { x } \\approx \\frac { 1 } { S } \\sum _ { s = 1 } ^ { S } w _ { s } f \\left( \\mathbf { x } ^ { s } \\right) = \\hat { I }$$\n",
    "\n",
    "where $w _ { s } \\triangleq \\frac { p \\left( \\mathbf { x } ^ { s } \\right) } { q \\left( \\mathbf { x } ^ { s } \\right) }$ are the importance weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Monte Carlo\n",
    "Work well in high dimensional data. \n",
    "\n",
    "Basic idea: to construct a markov chain on the state space $X$ whose stationary distribution is the target density $p^*(x)$ of interest (this may be a prior or a posterior). That is , we perfom a random walk on the state space, in such a way that the fraction of the time we spend in each state $x$ is proportional to $p^*(x)$. By drawing correlated samples $x_0, x_1, x_2, \\ldots,$ from the chain, we can perfrom the Monte Carlo integration w.r.t $p^*$.\n",
    "\n",
    "Compare to Variational Inference:\n",
    "+ MCMC: \n",
    "    * often easier to implement\n",
    "    * applicable to a broader range of models\n",
    "    * sampling can be faster than variational methods when applied to really hunge models or datasets.\n",
    "+ VI: \n",
    "    * faster for small to medium problems\n",
    "    * deterministic\n",
    "    * easy to determine when to stop\n",
    "    * provides a lower bound on the log likelihood\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs sampling\n",
    "MCMC analog of coordinate descent\n",
    "\n",
    "Basic idea: we sample each variable in turn, conditioned on the values of all the other variables in the distribution. Given a joint sample $x^s$ of all the variables, we generate a new sample $x^{s+1}$ by sampling each component in turn, based on the most recent values of other variables. For example, if we have $D=3$ variables, we use:\n",
    "\n",
    "$$\\begin{aligned} x _ { 1 } ^ { s + 1 } & \\sim p \\left( x _ { 1 } | x _ { 2 } ^ { s } , x _ { 3 } ^ { s } \\right) \\\\ x _ { 2 } ^ { s + 1 } & \\sim p \\left( x _ { 2 } | x _ { 1 } ^ { s + 1 } , x _ { 3 } ^ { s } \\right) \\\\ x _ { 3 } ^ { s + 1 } & \\sim p \\left( x _ { 3 } | x _ { 1 } ^ { s + 1 } , x _ { 2 } ^ { s + 1 } \\right) \\end{aligned}$$\n",
    "\n",
    "If $x_i$ is a visible variable, we do not sample it, since its value is already known. The expression $p \\left( x _ { i } | \\mathbf { x } _ { - i } \\right)$ is called the full conditional for variable $i$. To sample $x_i$, we only need to know the values of $i$'s neighbors. It is necessary to discard some of the initial samples until the Markov chain has burned in, or entered its stationary distribution. \n",
    "\n",
    "Example of Gibbs sampling in pairwise MRF/CRF:\n",
    "$$p \\left( x _ { t } | \\mathbf { x } _ { - t } , \\boldsymbol { \\theta } \\right) \\propto \\prod _ { s \\in \\operatorname { nbr } ( t ) } \\psi _ { s t } \\left( x _ { s } , x _ { t } \\right)$$\n",
    "\n",
    "$$p \\left( x _ { t } = + 1 | \\mathbf { x } _ { - t } , \\boldsymbol { \\theta } \\right) = \\operatorname { sigm } \\left( 2 J \\eta _ { t } \\right)$$\n",
    "\n",
    "### Metropolis Hastings algorithm\n",
    "For computing the posterior of graphical model that has no useful Markov structure, we use more general algorithm called Metropolis Hastings (MH)\n",
    "\n",
    "Basic idea: \n",
    "\n",
    "At each step, we propose to move from the current state $x$ toa new state $x'$ with probability $q(x'|x)$ where $q$ is called the proposal didstribution. \n",
    "+ A commonly used proposal is a symmetric Gaussian distribution centered on the current state, $q \\left( \\mathbf { x } ^ { \\prime } | \\mathbf { x } \\right) = \\mathcal { N } \\left( \\mathbf { x } ^ { \\prime } | \\mathbf { x } , \\mathbf { \\Sigma } \\right)$; This is called Random walk Metropolis algorithm.\n",
    "+ If we use a proposal of the form $q \\left( \\mathbf { x } ^ { \\prime } | \\mathbf { x } \\right) = q \\left( \\mathbf { x } ^ { \\prime } \\right)$, where the new state is independent of the old state, we get a method known as the independence sampler, which is similar to important sampling.\n",
    "\n",
    "Having proposed a move to $x'$, we then decide whether to accept this proposal or not according to some formula, which ensures taht the fraction of time spent in each state is proportional to $p^*(x)$. if the proposal is accepted, the new state is $x'$, otherwise the new state is the same as the current state $x$.\n",
    "\n",
    "+ If the proposal is symmetric, so $q \\left( \\mathbf { x } ^ { \\prime } | \\mathbf { x } \\right) = q ( \\mathbf { x } | \\mathbf { x } ^ { \\prime } )$, the acceptance probability is given by:\n",
    "$$r = \\min \\left( 1 , \\frac { p ^ { * } \\left( \\mathbf { x } ^ { \\prime } \\right) } { p ^ { * } ( \\mathbf { x } ) } \\right)$$\n",
    "+ If the proposal is asymmetric, so $q \\left( \\mathbf { x } ^ { \\prime } | \\mathbf { x } \\right) \\neq q ( \\mathbf { x } | \\mathbf { x } ^ { \\prime } )$, we need the Hastings correction, given by:\n",
    "$$\\begin{aligned} r & = \\min ( 1 , \\alpha ) \\\\ \\alpha & = \\frac { p ^ { * } \\left( \\mathbf { x } ^ { \\prime } \\right) q ( \\mathbf { x } | \\mathbf { x } ^ { \\prime } ) } { p ^ { * } ( \\mathbf { x } ) q \\left( \\mathbf { x } ^ { \\prime } | \\mathbf { x } \\right) } = \\frac { p ^ { * } \\left( \\mathbf { x } ^ { \\prime } \\right) / q \\left( \\mathbf { x } ^ { \\prime } | \\mathbf { x } \\right) } { p ^ { * } ( \\mathbf { x } ) / q ( \\mathbf { x } | \\mathbf { x } ^ { \\prime } ) } \\end{aligned}$$\n",
    "\n",
    "![](../images/26.MH.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
