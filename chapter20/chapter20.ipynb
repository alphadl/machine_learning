{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Inference for Graphical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute exactly the posterior marginals $p \\left( x _ { t } | \\mathbf { v } , \\boldsymbol { \\theta } \\right)$, where $\\mathbf(x)$ are hidden variables (discrete) and $\\mathbf{v}$ are the visible variables. The resulting methods apply to both directed and undirected graphical models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belief Propagation for trees\n",
    "Belief Progagation (BP) or sum-product algorithm\n",
    "\n",
    "### Serial Protocol\n",
    "\n",
    "The model is a pairwise MRF (or CRF):\n",
    "\n",
    "$$p ( \\mathbf { x } | \\mathbf { v } ) = \\frac { 1 } { Z ( \\mathbf { v } ) } \\prod _ { s \\in \\mathcal { V } } \\psi _ { s } \\left( x _ { s } \\right) \\prod _ { ( s , t ) \\in \\mathcal { E } } \\psi _ { s , t } \\left( x _ { s } , x _ { t } \\right)$$\n",
    "\n",
    "where $\\psi_s$ is the local evidence for node $s$, $\\psi_{s,t}$ is the pairwise potential for edge $s-t$. For undirected trees, we pick an arbitrary node and call it the root $r$. Now orient all edges away from $r$. This gives us a well-defined notion of parent and child. Now we send messages up from the leaves to the root (the **collect evidence** phase) and then back down from the root (the **distribute evidence** phase), in a manner analogous to forwards-backwards on chains.\n",
    "\n",
    "![](../images/20.BP.png)\n",
    "\n",
    "+ We compute the bottom-up belief state at $t$ as follows:\n",
    "$$\\mathrm { bel } _ { t } ^ { - } \\left( x _ { t } \\right) \\triangleq p \\left( x _ { t } | \\mathbf { v } _ { t } ^ { - } \\right) = \\frac { 1 } { Z _ { t } } \\psi _ { t } \\left( x _ { t } \\right) \\prod _ { c \\in \\operatorname { ch } ( t ) } m _ { c \\rightarrow t } ^ { - } \\left( x _ { t } \\right)$$\n",
    "\n",
    "+ We compute the bottom-up message:\n",
    "$$m _ { s \\rightarrow t } ^ { - } \\left( x _ { t } \\right) = \\sum _ { x _ { s } } \\psi _ { s t } \\left( x _ { s } , x _ { t } \\right) \\operatorname { bel } _ { s } ^ { - } \\left( x _ { s } \\right)$$\n",
    "\n",
    "+ Local belief at the root:\n",
    "$$\\operatorname { bel } _ { r } \\left( x _ { r } \\right) \\triangleq p \\left( x _ { r } | \\mathbf { v } \\right) = p \\left( x _ { t } | \\mathbf { v } _ { r } ^ { - } \\right) \\propto \\psi _ { r } \\left( x _ { r } \\right) \\prod _ { c \\in \\operatorname { ch } ( r ) } m _ { c \\rightarrow r } ^ { - } \\left( x _ { r } \\right)$$\n",
    "\n",
    "+ Probability of the evidence:\n",
    "$$p ( \\mathbf { v } ) = \\prod _ { t } Z _ { t }$$\n",
    "\n",
    "+ Top-down (real) belief:\n",
    "$$\\operatorname { bel } _ { s } \\left( x _ { s } \\right) \\triangleq p \\left( x _ { s } | \\mathbf { v } \\right) \\propto \\operatorname { bel } _ { s } ^ { - } \\left( x _ { s } \\right) \\prod _ { t \\in \\operatorname { pa } ( s ) } m _ { t \\rightarrow s } ^ { + } \\left( x _ { t } \\right)$$\n",
    "\n",
    "+ Downward message: \n",
    "$$m _ { t \\rightarrow s } ^ { + } \\left( x _ { s } \\right) \\triangleq p \\left( x _ { s } | \\mathbf { v } _ { s t } ^ { + } \\right) = \\sum _ { x _ { t } } \\psi _ { s t } \\left( x _ { s } , x _ { t } \\right) \\frac { \\operatorname { bel } _ { t } \\left( x _ { t } \\right) } { m _ { s \\rightarrow t } ^ { - } \\left( x _ { t } \\right) }$$\n",
    "\n",
    "### Parallel protocol\n",
    "The basic idea is taht all nodes receive messages from their neighbors in parallel, they then updates their belief states, and finally they send new messages back out to their neighbors. This process repeats until convergence.\n",
    "\n",
    "We initialize all messages to the all 1's vector. Then, in parallel, each node absorbs messages from all its neihbors using:\n",
    "$$\\operatorname { bel } _ { s } \\left( x _ { s } \\right) \\propto \\psi _ { s } \\left( x _ { s } \\right) \\prod _ { t \\in \\mathrm { nbr } _ { s } } m _ { t \\rightarrow s } \\left( x _ { s } \\right)$$\n",
    "\n",
    "Then in parallel, each nodes sends messages to each of its neighbors:\n",
    "$$m _ { s \\rightarrow t } \\left( x _ { t } \\right) = \\sum _ { x _ { s } } \\left( \\psi _ { s } \\left( x _ { s } \\right) \\psi _ { s t } \\left( x _ { s } , x _ { t } \\right) \\prod _ { u \\in \\mathrm { nbr } _ { s } \\backslash t } m _ { u \\rightarrow s } \\left( x _ { s } \\right) \\right)$$\n",
    "\n",
    "The $m_{s \\rightarrow t}$ message is computed by multiplying together all incoming messages, except the one sent by the recipient, and then passing through the $\\psi_{st}$ potential. At iteration T of the algorithm, $\\operatorname{bel}_s(x_s)$ represents the posterior belief of $x_s$ conditioned on the evidence that is $T$ steps away in the graph. After $D(G) steps, is the diameter of the graph, every node has obtained information from all other nodes. Its local belief state is then the correct posterior marginal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
